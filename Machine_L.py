# -*- coding: utf-8 -*-
"""final minor1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uQbCIplca2mHOwAkmbD4wQpDUafg9DPi
"""

!pip install catboost
!pip install xgboost
!pip install imblearn

# Libraries for Data Manipulation

import numpy as np
import pandas as pd
from scipy.stats import skew


# Libraries for Data Visualization
import seaborn as sns
import matplotlib.pyplot as plt
import altair as alt
from scipy.stats import skew
import matplotlib.ticker as ticker
import pickle

# Libraries to Handle Warnings
import warnings
warnings.filterwarnings('ignore')

# Libraries for Statistical Analysis
from scipy import stats
from scipy.stats import chi2, chi2_contingency

# Machine Learning Algorithms
import numpy as np
import pandas as pd
from sklearn.datasets import make_blobs
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.metrics import classification_report, accuracy_score

from sklearn.utils.class_weight import compute_class_weight
import pandas as pd
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import mutual_info_regression
from sklearn.decomposition import PCA
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.preprocessing import LabelEncoder, OneHotEncoder

from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline
from sklearn.neighbors import KNeighborsClassifier

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score
import warnings
from sklearn.exceptions import DataConversionWarning
from sklearn.ensemble import GradientBoostingClassifier

from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
from sklearn.ensemble import VotingClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from catboost import CatBoostClassifier

##data_path = "/content/"
# Path to the Kaggle input folder
data_path = "/content/"

# Load CSV files
testing_set = pd.read_csv(data_path + "UNSW_NB15_testing-set.csv")
training_set = pd.read_csv(data_path + "UNSW_NB15_training-set.csv")
LIST_EVENTS = pd.read_csv(data_path + "UNSW-NB15_LIST_EVENTS.csv")
NB15_1 = pd.read_csv(data_path + "UNSW-NB15_1.csv")
NB15_2 = pd.read_csv(data_path + "UNSW-NB15_2.csv")
NB15_3 = pd.read_csv(data_path + "UNSW-NB15_3.csv")
NB15_4 = pd.read_csv(data_path + "UNSW-NB15_4.csv")
NB15_features = pd.read_csv(data_path + "NUSW-NB15_features.csv", encoding='cp1252')

# Check if data is loaded correctly
print(training_set.shape, testing_set.shape)

testing_set.head()

training_set.head()

LIST_EVENTS.head()

NB15_1.head()

NB15_2.head()

NB15_3.head()

NB15_4.head()

NB15_features

"""merging the tables"""

NB15_1.columns = NB15_features['Name']
NB15_2.columns = NB15_features['Name']
NB15_3.columns = NB15_features['Name']
NB15_4.columns = NB15_features['Name']

train_df = pd.concat([NB15_1, NB15_2, NB15_3, NB15_4], ignore_index=True)

train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)

train_df.sample()

print("dataset shape: ",train_df.shape)

train_df.info()

numerical_columns = train_df.select_dtypes(include=['number']).columns
categorical_columns = train_df.select_dtypes(exclude=['number']).columns
print(f"There are {len(numerical_columns)} Numerical Columns in the dataset.")
print(f"There are {len(categorical_columns)} Categorical Columns in the dataset.")

duplicate_count = train_df.duplicated().sum()
print(f"Duplicates in train_df: {duplicate_count}")

train_df = train_df.drop_duplicates()

print(f"New dataset shape after removing duplicates: {train_df.shape}")

missing_data = train_df.isnull().sum().reset_index()
missing_data.columns = ["Column Name", "Total Missing Values"]
missing_data["% Missing"] = (missing_data["Total Missing Values"] / len(train_df) * 100).round(2)

missing_data = missing_data[missing_data["Total Missing Values"] > 0].sort_values(by="% Missing", ascending=False)

missing_data

"""

---



---


Handling Missing Values in 'attack_cat'



---



---

"""

if 'label' in train_df.columns:
    train_df.loc[(train_df['attack_cat'].isna()) & (train_df['label'] == 1), 'attack_cat'] = 'unknown_attack'

train_df['attack_cat'].fillna('normal', inplace=True)

train_df['attack_cat'] = train_df['attack_cat'].str.strip().str.lower()

"""

---



---

Handling 'ct_flw_http_mthd' (Number of HTTP Flows)


---


---


"""

http_mode = train_df['ct_flw_http_mthd'].mode()[0]

fill_value = 0 if http_mode == 0 else http_mode
train_df['ct_flw_http_mthd'].fillna(fill_value, inplace=True)

"""

---



---



Handling 'is_ftp_login' (Binary Feature)


---



---

"""

train_df['is_ftp_login'] = train_df['is_ftp_login'].fillna(
    train_df.groupby('proto')['is_ftp_login'].transform(lambda x: x.mode()[0] if not x.mode().empty else 0)
)

"""Checking if any missing values are still present in the dataset"""

missing_data = train_df.isnull().sum().to_frame().rename(columns={0: "Total Missing Values"})
missing_data["% Missing"] = round((missing_data["Total Missing Values"] / len(train_df)) * 100, 2)

missing_data = missing_data[missing_data["Total Missing Values"] > 0]

if missing_data.empty:
    print("No missing values left in the dataset! ")
else:
    print("Remaining missing values:\n", missing_data)

print("Summary Statistics for Numerical Columns:")
display(train_df.describe().T)

print("\nSummary Statistics for Categorical Columns:")
display(train_df.describe(include=['object']).T)

unique_values_summary = []

for column in train_df.columns:
    unique_count = train_df[column].nunique()
    unique_values = train_df[column].unique()[:10]

    unique_values_summary.append({
        "Column Name": column,
        "Data Type": train_df[column].dtype,
        "Total Unique Values": unique_count,
        "Sample Unique Values": unique_values
    })

unique_values_df = pd.DataFrame(unique_values_summary)

display(unique_values_df)

train_df['ct_ftp_cmd'] = train_df['ct_ftp_cmd'].replace(' ', '0').fillna(0).astype(int)

print(train_df['ct_ftp_cmd'].dtype)
print(train_df['ct_ftp_cmd'].unique()[:10])

def convert_to_binary(df, column):
    df[column] = df[column].fillna(0)
    df[column] = (df[column] > 0).astype(int)
    return df

column = 'is_ftp_login'
convert_to_binary(train_df, column)

train_df['sport'] = pd.to_numeric(train_df['sport'], errors='coerce').astype('Int64')
train_df['dsport'] = pd.to_numeric(train_df['dsport'], errors='coerce').astype('Int64')

numerical_columns = train_df.select_dtypes(include=['int64', 'float64']).columns
print(f"Total Numerical Columns: {len(numerical_columns)}")
print("Numerical Columns:", numerical_columns.tolist())

plt.figure(figsize=(15, 6))
train_df[numerical_columns].boxplot(rot=90)
plt.title("Boxplot of Numerical Columns (Checking Outliers)")
plt.savefig("Boxplot of Numerical Columns (Checking Outliers).png")
plt.show()

def transform(X):
    eps = 1e-5
    numerical_columns = X.select_dtypes(include=['float64', 'int64']).columns.tolist()

    for col in numerical_columns:
        skewness = skew(X[col].dropna())
        if skewness > 0:
            X[col] = np.log(X[col] + eps)
        elif skewness < 0:  # Negative skew
            X[col] = np.log(np.max(X[col]) - X[col] + eps)
        else:
            X[col] = X[col]

    return X

train_df_transformed = transform(train_df.copy())

def pie_bar_plot(df, col):
    plt.figure(figsize=(10, 6))

    # Extract value counts for the specified column
    value_counts = df[col].value_counts().sort_index()

    # Plot pie chart
    plt.title(f"Distribution by {col}", fontweight="black", size=14, pad=15)
    colors = sns.color_palette('Set2', len(value_counts))
    plt.pie(value_counts.values, labels=value_counts.index, autopct='%1.1f%%', startangle=90, colors=colors)

    # Add center circle to create a donut chart effect
    center_circle = plt.Circle((0, 0), 0.4, fc='white')
    fig = plt.gcf()
    fig.gca().add_artist(center_circle)

    # Display the plot
    plt.show()

# Call the function to check class distribution on the 'label' column (adjust column name if necessary)
pie_bar_plot(train_df, 'attack_cat')

# Print class distribution before resampling
print("Before resampling:", train_df['attack_cat'].value_counts())
print()

def generate_features(df):
    # Duration
    df['duration'] = df['Ltime'] - df['Stime']

    # Ratios
    df['byte_ratio'] = df['sbytes'] / (df['dbytes'] + 1)
    df['pkt_ratio'] = df['Spkts'] / (df['Dpkts'] + 1)
    df['load_ratio'] = df['Sload'] / (df['Dload'] + 1)
    df['jit_ratio'] = df['Sjit'] / (df['Djit'] + 1)
    df['inter_pkt_ratio'] = df['Sintpkt'] / (df['Dintpkt'] + 1)
    df['tcp_setup_ratio'] = df['tcprtt'] / (df['synack'] + df['ackdat'] + 1)

    # Aggregate Features
    df['total_bytes'] = df['sbytes'] + df['dbytes']
    df['total_pkts'] = df['Spkts'] + df['Dpkts']
    df['total_load'] = df['Sload'] + df['Dload']
    df['total_jitter'] = df['Sjit'] + df['Djit']
    df['total_inter_pkt'] = df['Sintpkt'] + df['Dintpkt']
    df['total_tcp_setup'] = df['tcprtt'] + df['synack'] + df['ackdat']

    # Interaction Features
    df['byte_pkt_interaction_src'] = df['sbytes'] * df['Spkts']
    df['byte_pkt_interaction_dst'] = df['dbytes'] * df['Dpkts']
    df['load_jit_interaction_src'] = df['Sload'] * df['Sjit']
    df['load_jit_interaction_dst'] = df['Dload'] * df['Djit']
    df['pkt_jit_interaction_src'] = df['Spkts'] * df['Sjit']
    df['pkt_jit_interaction_dst'] = df['Dpkts'] * df['Djit']

    # Statistical Features
    df['mean_pkt_size'] = df['smeansz'] + df['dmeansz']
    df['tcp_seq_diff'] = df['stcpb'] - df['dtcpb']

    return df

generate_features(train_df)

# Drop the specified columns from both train_df and test_df
columns_to_drop = ['sport', 'dsport', 'proto','srcip', 'dstip','state', 'service']
train_df.drop(columns=columns_to_drop, inplace=True)

#Checking the categorical columns
cat_columns = train_df.select_dtypes(include=['O']).columns.tolist()
cat_columns

label_encoder = LabelEncoder()
ohe = OneHotEncoder()

train_df['attack_cat'] = label_encoder.fit_transform(train_df['attack_cat'])

label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))
print("Label Mapping:")
print(label_mapping)

plt.figure(figsize=(40,20))
plt.title("Correlation Plot")
sns.heatmap(train_df.corr(),cmap='YlGnBu')

# Calculate the correlation matrix
correlation_matrix = train_df.corr()

# Create a mask to identify the features with a correlation coefficient greater than or equal to 0.75
high_correlation_mask = correlation_matrix >= 0.75

# Identify and list the highly correlated features
highly_correlated_features = []

for feature in high_correlation_mask.columns:
    correlated_with = high_correlation_mask.index[high_correlation_mask[feature]].tolist()
    for correlated_feature in correlated_with:
        if feature != correlated_feature and (correlated_feature, feature) not in highly_correlated_features:
            highly_correlated_features.append((feature, correlated_feature))

# Print the highly correlated features
print("Highly correlated features:")
for feature1, feature2 in highly_correlated_features:
    print(f"{feature1} and {feature2}")

# Create a set of features to drop
features_to_drop = set()

# Iterate over the highly correlated features and add one of each pair to the drop list
for feature1, feature2 in highly_correlated_features:
    if feature1 not in features_to_drop and feature2 not in features_to_drop:
        features_to_drop.add(feature2)

# Drop the features from the DataFrame
train_df = train_df.drop(columns=features_to_drop)

# Print the remaining features
print("Remaining features after dropping highly correlated ones:")
print(train_df.columns)

x = train_df.drop(['attack_cat'], axis=1)
y = train_df[['attack_cat']]

# Define the desired number of samples for each class
desired_count = 15000

# Define the oversampling strategy for SMOTE
oversample_strategy = {i: desired_count for i in range(len(y.value_counts())) if y.value_counts()[i] < desired_count}

# Define the undersampling strategy for RandomUnderSampler
undersample_strategy = {i: desired_count for i in range(len(y.value_counts())) if y.value_counts()[i] > desired_count}

# Create the SMOTE and RandomUnderSampler objects
smote = SMOTE(sampling_strategy=oversample_strategy)
undersample = RandomUnderSampler(sampling_strategy=undersample_strategy)

# Combine SMOTE and RandomUnderSampler in a pipeline
pipeline = Pipeline(steps=[('smote', smote), ('undersample', undersample)])

# Print class distribution before resampling
print("Before resampling:", y.value_counts())
print()

# Apply the pipeline to resample the dataset
x_resampled, y_resampled = pipeline.fit_resample(x, y)

# Print class distribution after resampling
print("After resampling:", y_resampled.value_counts())

x = x_resampled
y = y_resampled

from sklearn.feature_selection import mutual_info_classif

def mi_score_maker(x, y, discrete_features):
    scores = mutual_info_classif(x, y, discrete_features=discrete_features, random_state=42, n_neighbors=3)
    df = pd.DataFrame({
        'Features': x.columns,
        'Scores': scores
    })
    df = df.sort_values(by='Scores', ascending=False).reset_index(drop=True)
    return df

y = y.astype(int)
mi_scores = mi_score_maker(x, y, discrete_features)
mi_scores

plt.figure(figsize=(10, 8))

# Create the barplot
sns.barplot(x='Scores', y='Features', data=mi_scores)

# Add a title
plt.title("Mutual Information Scores", fontsize=16)

# Rotate the y-axis labels (if needed)
plt.yticks(rotation=0)

# Rotate the x-axis labels (if needed)
plt.xticks(rotation=45)

# Display the plot
plt.tight_layout()  # Adjusts the plot to ensure everything fits without overlap
plt.savefig("Mutual Information Scores.png")
plt.show()

selected_features = ["sbytes", "byte_ratio","byte_pkt_interaction_dst", "smeansz", "dbytes",
                     "Sload", "Stime", "dmeansz","duration"]

# Select only the chosen features from the resampled dataset
X_selected = x_resampled[selected_features]  # Resampled X with selected features
y_selected = y_resampled  # Target variable remains the same

# Display the first few rows of the updated dataset
print("Selected Features (X):\n", X_selected.head())
print("\nTarget Variable (y):\n", y_selected.head())

x_train, x_test, y_train, y_test = train_test_split(X_selected, y_selected, test_size=0.2, random_state=42)

# Initialize StandardScaler
scaler = StandardScaler()

# Fit the scaler ONLY on x_train
scaler.fit(x_train)

# Transform x_train and x_test using the trained scaler
x_train_scaled = scaler.transform(x_train)
x_test_scaled = scaler.transform(x_test)

# Convert back to DataFrame (optional for readability)
x_train_scaled_df = pd.DataFrame(x_train_scaled, columns=x_train.columns)
x_test_scaled_df = pd.DataFrame(x_test_scaled, columns=x_test.columns)

# Display the first few rows
print("Scaled Training Features:\n", x_train_scaled_df.head())
print("Scaled Testing Features:\n", x_test_scaled_df.head())

warnings.filterwarnings(action='ignore', category=DataConversionWarning)

from sklearn.model_selection import RandomizedSearchCV

param_dist = {
    'n_estimators': [200, 500, 1000],
    'max_depth': [10, 20, None],
    'min_samples_split': [2, 5, 10],
    'class_weight': ['balanced', None]
}

rf_model = RandomForestClassifier(random_state=42)
search_rf = RandomizedSearchCV(
    rf_model,
    param_distributions=param_dist,
    n_iter=10,
    scoring='f1_macro',  # use f1_macro for imbalanced multiclass
    cv=3,
    n_jobs=-1,
    verbose=1
)

search_rf.fit(x_train_scaled, y_train)

best_rf = search_rf.best_estimator_
rf_y_pred = best_rf.predict(x_test_scaled)

print("Tuned Random Forest Classification Report:")
print(classification_report(y_test, rf_y_pred))
print("Random Forest Accuracy:", accuracy_score(y_test, rf_y_pred))

import pickle
# Saving Random Forest model
with open('rf_model.pkl', 'wb') as f:
    pickle.dump(rf_model, f)

from sklearn.model_selection import GridSearchCV
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, accuracy_score

params_knn = {
    'n_neighbors': [3, 5, 7, 11],
    'weights': ['uniform', 'distance'],
    'metric': ['euclidean', 'manhattan']
}

knn = KNeighborsClassifier()
search_knn = GridSearchCV(knn, params_knn, cv=3, scoring='f1_macro', n_jobs=-1, verbose=1)
search_knn.fit(x_train_scaled, y_train)

best_knn = search_knn.best_estimator_
knn_y_pred = best_knn.predict(x_test_scaled)

print("Tuned KNN Classification Report:")
print(classification_report(y_test, knn_y_pred))
print("Tuned KNN Accuracy:", accuracy_score(y_test, knn_y_pred))

with open('knn_model.pkl', 'wb') as f:
    pickle.dump(knn_model, f)

from sklearn.model_selection import RandomizedSearchCV
from xgboost import XGBClassifier

xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)

param_grid = {
    'n_estimators': [100, 200, 300],
    'learning_rate': [0.01, 0.05, 0.1],
    'max_depth': [4, 6, 8],
    'subsample': [0.8, 1],
    'colsample_bytree': [0.8, 1]
}

xgb_search = RandomizedSearchCV(xgb, param_grid, scoring='f1_macro', n_iter=10, cv=3, n_jobs=-1, verbose=1)
xgb_search.fit(x_train_scaled, y_train)

best_xgb = xgb_search.best_estimator_
xgb_y_pred = best_xgb.predict(x_test_scaled)

print("XGBoost Classification Report:")
print(classification_report(y_test, xgb_y_pred))

# Saving xgBoost model with pickle
with open('xgb_model.pkl', 'wb') as f:
    pickle.dump(xgb_model, f)

rf = RandomForestClassifier(n_estimators=200)
xgb = XGBClassifier(n_estimators=300, learning_rate=0.05)
cat = CatBoostClassifier(iterations=300, learning_rate=0.05, depth=6, verbose=0)


ensemble = VotingClassifier(
    estimators=[('rf', rf), ('xgb', xgb), ('cat', cat)],
    voting='soft',
    weights=[1, 2, 2]  # XGBoost & CatBoost ko zyada weight diya
)

ensemble.fit(x_train_scaled, y_train)

vt_y_pred = ensemble.predict(x_test_scaled)

# Generate the classification report

print("Accuracy:", accuracy_score(y_test, vt_y_pred))

report = classification_report(y_test, vt_y_pred)
print(report)

# Save report to a text file
with open("classification_report.txt", "w") as f:
    f.write(report)

print("Classification report saved as classification_report.txt")

# Generate confusion matrix
cm = confusion_matrix(y_test, vt_y_pred)

# Plot confusion matrix
plt.figure(figsize=(10, 7))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=set(y_test), yticklabels=set(y_test))
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix - Ensemble Model')
plt.savefig('Confusion Matrix - Ensemble Model.png')
plt.show()

# Save the trained ensemble model
import joblib

# Save the entire ensemble model
joblib.dump(ensemble, "voting_model.pkl")

print("Model saved successfully using joblib!")

# Save the scaler (important for inference)
joblib.dump(scaler, "scaler.pkl")
